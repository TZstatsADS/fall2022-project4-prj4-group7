{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abd07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(1, '../lib/')\n",
    "import util as ut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d27502",
   "metadata": {},
   "source": [
    "## Data Clean, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9651d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "compas = pd.read_csv('../data/compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4444a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "compas = compas[compas.race.isin(['Caucasian','African-American'])]\n",
    "compas = compas[(compas.days_b_screening_arrest <= 30) & (compas.days_b_screening_arrest >= -30)]\n",
    "compas = compas[compas.is_recid != -1]\n",
    "compas = compas[compas.c_charge_degree != \"O\"]\n",
    "compas = compas[compas.score_text != \"N/A\"]\n",
    "\n",
    "cleanup_nums = {\"sex\":     {\"Male\": 0, \"Female\": 1},\n",
    "                \"age_cat\": {\"25 - 45\": 0, \"Less than 25\": 1, \"Greater than 45\": 2},\n",
    "                \"race\": {\"African-American\": 1, \"Caucasian\": 0},\n",
    "                \"c_charge_degree\": {\"F\": 0, \"M\": 1},\n",
    "                \"score_text\": {\"Low\": 0, \"Medium\": 1, \"High\": 2}}\n",
    "compas = compas.replace(cleanup_nums)\n",
    "\n",
    "compas[\"length_of_stay\"] = (pd.to_datetime(compas.c_jail_out) - pd.to_datetime(compas.c_jail_in)).astype('timedelta64[D]')\n",
    "\n",
    "X = [\"age\", \"c_charge_degree\", \"age_cat\", \"sex\", \"priors_count\", \"length_of_stay\"]\n",
    "S = [\"race\"]\n",
    "features = [\"age\", \"c_charge_degree\", \"age_cat\", \"sex\", \"priors_count\", \"length_of_stay\", \"race\"]\n",
    "Y = [\"two_year_recid\"]\n",
    "\n",
    "compas.to_csv('../output/compas-scores-two-years_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ba0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training\n",
    "x_train, x_test, y_train, y_test = train_test_split(compas[features], compas[Y], test_size=0.1, random_state=42)\n",
    "\n",
    "x_train=x_train.reset_index()\n",
    "x_test=x_test.reset_index()\n",
    "y_train=y_train.reset_index()\n",
    "y_test=y_test.reset_index()\n",
    "\n",
    "\n",
    "X_train = x_train[X]\n",
    "S_train = x_train[S]\n",
    "\n",
    "X_test = x_test[X]\n",
    "S_test = x_test[S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d7912",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf8b0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.6738947368421052\n",
      "test accuracy: 0.6609848484848485\n",
      "train calibration: 0.007050538563553199\n",
      "test calibration: 0.011778846153846168\n"
     ]
    }
   ],
   "source": [
    "model_base = LogisticRegression(fit_intercept=False).fit(x_train,y_train[Y].values.flatten())\n",
    "base_y_train = model_base.predict(x_train)\n",
    "base_y_test = model_base.predict(x_test)\n",
    "\n",
    "#metrics\n",
    "print('train accuracy: ' + str(model_base.score(x_train,y_train[Y].values.flatten())))\n",
    "print('test accuracy: ' + str(model_base.score(x_test,y_test[Y].values.flatten())))\n",
    "\n",
    "base_calib_train = ut.calibration(x_train, base_y_train, y_train[Y].values.flatten())\n",
    "base_calib_test = ut.calibration(x_test, base_y_test, y_test[Y].values.flatten())\n",
    "\n",
    "print('train calibration: ' + str(base_calib_train))\n",
    "print('test calibration: ' + str(base_calib_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb351e",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f11cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4686315789473684\n",
      "test accuracy: 0.48674242424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train calibration difference: 0.13350091724466173\n",
      "test calibration difference: 0.12091346153846161\n"
     ]
    }
   ],
   "source": [
    "theta_g = ut.model_gamma(x_train,y_train[Y].values.flatten(),S_train[S].values.flatten(),base_y_train)\n",
    "\n",
    "#to use score\n",
    "model_gamma = LogisticRegression()\n",
    "model_gamma.coef_ = theta_g.reshape((1,-1))\n",
    "model_gamma.intercept_ = 0\n",
    "model_gamma.classes_ = np.array([0,1])\n",
    "g_y_train = model_gamma.predict(x_train)\n",
    "g_y_test = model_gamma.predict(x_test)\n",
    "\n",
    "#metrics\n",
    "print('train accuracy: ' + str(model_gamma.score(x_train,y_train[Y].values.flatten())))\n",
    "print('test accuracy: ' + str(model_gamma.score(x_test,y_test[Y].values.flatten())))\n",
    "\n",
    "g_calib_train = ut.calibration(x_train, g_y_train, y_train[Y].values.flatten())\n",
    "g_calib_test = ut.calibration(x_test, g_y_test, y_test[Y].values.flatten())\n",
    "\n",
    "print('train calibration difference: ' + str(g_calib_train))\n",
    "print('test calibration difference: ' + str(g_calib_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c46ea1",
   "metadata": {},
   "source": [
    "## Fine-grained Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61aef51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\samee\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4686315789473684\n",
      "test accuracy: 0.48674242424242425\n",
      "train calibration difference: 0.13350091724466173\n",
      "test calibration difference: 0.12091346153846161\n"
     ]
    }
   ],
   "source": [
    "theta_fg = ut.model_fg(x_train.values,y_train[Y].values.flatten(),S_train[S].values.flatten(),base_y_train)\n",
    "\n",
    "#to use score\n",
    "model_fine_gamma = LogisticRegression()\n",
    "model_fine_gamma.coef_ = theta_fg.reshape((1,-1))\n",
    "model_fine_gamma.intercept_ = 0\n",
    "model_fine_gamma.classes_ = np.array([0,1])\n",
    "fg_y_train = model_fine_gamma.predict(x_train)\n",
    "fg_y_test = model_fine_gamma.predict(x_test)\n",
    "\n",
    "#metrics\n",
    "print('train accuracy: ' + str(model_fine_gamma.score(x_train,y_train[Y].values.flatten())))\n",
    "print('test accuracy: ' + str(model_fine_gamma.score(x_test,y_test[Y].values.flatten())))\n",
    "\n",
    "fg_calib_train = ut.calibration(x_train, fg_y_train, y_train[Y].values.flatten())\n",
    "fg_calib_test = ut.calibration(x_test, fg_y_test, y_test[Y].values.flatten())\n",
    "\n",
    "print('train calibration difference: ' + str(fg_calib_train))\n",
    "print('test calibration difference: ' + str(fg_calib_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31716c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
