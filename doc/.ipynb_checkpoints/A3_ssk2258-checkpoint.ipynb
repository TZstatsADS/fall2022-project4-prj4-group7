{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abd07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#imports\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(1, '../lib/')\n",
    "import util as ut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d27502",
   "metadata": {},
   "source": [
    "## Data Clean, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9651d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "raw_data = '../data/compas-scores-two-years.csv'\n",
    "df = pd.read_csv(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4444a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "\n",
    "data = df[(df['race']=='African-American')|(df['race']=='Caucasian')]\n",
    "data[\"length_of_stay\"] = (pd.to_datetime(data.c_jail_out) - pd.to_datetime(data.c_jail_in)).astype('timedelta64[D]')\n",
    "data = data[(data.days_b_screening_arrest <= 30) & (data.days_b_screening_arrest >= -30)]\n",
    "data = data[data.is_recid != -1]\n",
    "data = data[data.c_charge_degree != \"O\"]\n",
    "data = data[data.score_text != \"N/A\"]\n",
    "data.drop(['first','last','c_case_number','c_charge_desc','violent_recid','vr_charge_degree','vr_case_number','vr_offense_date','vr_charge_desc',\n",
    "          'c_arrest_date','r_jail_out','r_jail_in','r_days_from_arrest','r_charge_desc',\n",
    "          'r_offense_date','r_case_number','r_charge_degree'], axis=1,inplace=True)\n",
    "data['c_days_from_compas'] = data['c_days_from_compas'] .fillna(data['c_days_from_compas'].mode()[0])\n",
    "data = data.dropna()\n",
    "X = data.drop(['id','two_year_recid','dob','name','v_type_of_assessment','type_of_assessment'], axis=1)\n",
    "X.set_index(data.id,inplace=True)\n",
    "y = data[['two_year_recid']]\n",
    "y.set_index(data.id,inplace=True)\n",
    "X = X.drop(['c_offense_date','c_jail_in','c_jail_out','out_custody','in_custody','screening_date','compas_screening_date','v_screening_date'],axis=1)\n",
    "#convert categorical variables into numeric\n",
    "X['race']= X['race'].replace(['African-American','Caucasian'],[0,1.0])\n",
    "X['sex'] = X['sex'].replace(['Male','Female'],[0,1.0])\n",
    "X['age_cat'] = X['age_cat'].replace(['25 - 45','Less than 25', 'Greater than 45'],[0,1.0,2.0])\n",
    "X['c_charge_degree'] = X['c_charge_degree'].replace(['M','F'],[0,1.0])\n",
    "X['score_text'] = X['score_text'].replace(['Low', 'High', 'Medium'],[0,1.0,2.0])\n",
    "X['v_score_text'] = X['v_score_text'].replace(['Low', 'High', 'Medium'],[0,1.0,2.0])\n",
    "X = X.fillna(0)\n",
    "\n",
    "#compas = compas[compas.race.isin(['Caucasian','African-American'])]\n",
    "#compas = compas[(compas.days_b_screening_arrest <= 30) & (compas.days_b_screening_arrest >= -30)]\n",
    "#compas = compas[compas.is_recid != -1]\n",
    "#compas = compas[compas.c_charge_degree != \"O\"]\n",
    "#compas = compas[compas.score_text != \"N/A\"]\n",
    "\n",
    "#cleanup_nums = {\"sex\":     {\"Male\": 0, \"Female\": 1},\n",
    "#                \"age_cat\": {\"25 - 45\": 0, \"Less than 25\": 1, \"Greater than 45\": 2},\n",
    "#                \"race\": {\"African-American\": 1, \"Caucasian\": 0},\n",
    "#                \"c_charge_degree\": {\"F\": 0, \"M\": 1},\n",
    "#                \"score_text\": {\"Low\": 0, \"Medium\": 1, \"High\": 2}}\n",
    "#compas = compas.replace(cleanup_nums)\n",
    "\n",
    "#compas[\"length_of_stay\"] = (pd.to_datetime(compas.c_jail_out) - pd.to_datetime(compas.c_jail_in)).astype('timedelta64[D]')\n",
    "\n",
    "#X = [\"age\", \"c_charge_degree\", \"age_cat\", \"sex\", \"priors_count\", \"length_of_stay\"]\n",
    "#S = [\"race\"]\n",
    "#features = [\"age\", \"c_charge_degree\", \"age_cat\", \"sex\", \"priors_count\", \"length_of_stay\", \"race\"]\n",
    "#Y = [\"two_year_recid\"]\n",
    "\n",
    "#compas.to_csv('../output/compas-scores-two-years_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ba0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training\n",
    "\n",
    "y=np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1,random_state=44)\n",
    "x_sensitive_tr = X_train.loc[:, 'race']\n",
    "x_sensitive_te = X_test.loc[:, 'race']\n",
    "X_train = X_train.loc[:, X_train.columns != 'race']\n",
    "X_test = X_test.loc[:, X_test.columns != 'race']\n",
    "\n",
    "X_train=X_train.reset_index()\n",
    "X_test=X_test.reset_index()\n",
    "x_sensitive_tr=x_sensitive_tr.reset_index()\n",
    "x_sensitive_te=x_sensitive_te.reset_index()\n",
    "\n",
    "X_train=X_train.drop(['id'], axis=1)\n",
    "X_test=X_test.drop(['id'], axis=1)\n",
    "x_sensitive_tr=x_sensitive_tr.drop(['id'], axis=1)\n",
    "x_sensitive_te=x_sensitive_te.drop(['id'], axis=1)\n",
    "\n",
    "#X_train = x_train[X]\n",
    "#S_train = x_train[S]\n",
    "\n",
    "#X_test = x_test[X]\n",
    "#S_test = x_test[S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d7912",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf8b0df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9639225181598063\n",
      "test accuracy: 0.9564270152505446\n",
      "train calibration: 0.0013216642186006933\n",
      "test calibration: -0.010360962566844933\n"
     ]
    }
   ],
   "source": [
    "model_base = LogisticRegression(fit_intercept=False).fit(X_train,y_train.flatten())\n",
    "base_y_train = model_base.predict(X_train)\n",
    "base_y_test = model_base.predict(X_test)\n",
    "\n",
    "theta_star = model_base.coef_.flatten()\n",
    "\n",
    "#metrics\n",
    "print('train accuracy: ' + str(model_base.score(X_train,y_train.flatten())))\n",
    "print('test accuracy: ' + str(model_base.score(X_test,y_test.flatten())))\n",
    "\n",
    "base_calib_train = ut.calibration(base_y_train, y_train.flatten(),x_sensitive_tr['race'].values)\n",
    "base_calib_test = ut.calibration(base_y_test, y_test.flatten(),x_sensitive_tr['race'].values)\n",
    "\n",
    "print('train calibration: ' + str(base_calib_train))\n",
    "print('test calibration: ' + str(base_calib_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb351e",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f11cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gamma =  0\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.001\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.01\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.05\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.1\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.15\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n",
      "Using gamma =  0.2\n",
      "train accuracy: 0.47893462469733655\n",
      "test accuracy: 0.5032679738562091\n",
      "train calibration difference: 0.13196630217683586\n",
      "test calibration difference: 0.05514705882352944\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(ut)\n",
    "\n",
    "for g in [0,0.001,0.01,0.05,0.1,0.15,0.2]:\n",
    "    print('Using gamma = ',g)\n",
    "\n",
    "    theta_g = ut.model_gamma(X_train,y_train.flatten(),x_sensitive_tr['race'].values,theta_star,g)\n",
    "   \n",
    "    #to use score\n",
    "    model_gamma = LogisticRegression(fit_intercept=False)\n",
    "    model_gamma.coef_ = theta_g.reshape((1,-1))\n",
    "    model_gamma.intercept_ = 0\n",
    "    model_gamma.classes_ = np.array([0,1.0])\n",
    "    g_y_train = model_gamma.predict(X_train)\n",
    "    g_y_test = model_gamma.predict(X_test)\n",
    "\n",
    "    #metrics\n",
    "    print('train accuracy: ' + str(model_gamma.score(X_train,y_train.flatten())))\n",
    "    print('test accuracy: ' + str(model_gamma.score(X_test,y_test.flatten())))\n",
    "\n",
    "    g_calib_train = ut.calibration(g_y_train, y_train.flatten(),x_sensitive_tr['race'].values)\n",
    "    g_calib_test = ut.calibration(g_y_test, y_test.flatten(),x_sensitive_tr['race'].values)\n",
    "\n",
    "    print('train calibration difference: ' + str(g_calib_train))\n",
    "    print('test calibration difference: ' + str(g_calib_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c46ea1",
   "metadata": {},
   "source": [
    "## Fine-grained Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61aef51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gamma =  0.1\n",
      "train accuracy: 0.47046004842615013\n",
      "test accuracy: 0.49019607843137253\n",
      "train calibration difference: 0.13672643056429867\n",
      "test calibration difference: 0.05113636363636359\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(ut)\n",
    "\n",
    "for g in [0.1]:\n",
    "    \n",
    "    print('Using gamma = ',g)\n",
    "    \n",
    "    \n",
    "    theta_fg = ut.model_fg(X_train.values,y_train.flatten(),x_sensitive_tr['race'].values,theta_star,g)\n",
    "\n",
    "    #to use score\n",
    "    model_fine_gamma = LogisticRegression(fit_intercept=False)\n",
    "    model_fine_gamma.coef_ = theta_fg.reshape((1,-1))\n",
    "    model_fine_gamma.intercept_ = 0\n",
    "    model_fine_gamma.classes_ = np.array([0,1.0])\n",
    "    fg_y_train = model_fine_gamma.predict(X_train)\n",
    "    fg_y_test = model_fine_gamma.predict(X_test)\n",
    "\n",
    "    #metrics\n",
    "    print('train accuracy: ' + str(model_fine_gamma.score(X_train,y_train.flatten())))\n",
    "    print('test accuracy: ' + str(model_fine_gamma.score(X_test,y_test.flatten())))\n",
    "\n",
    "    fg_calib_train = ut.calibration(fg_y_train, y_train.flatten(),x_sensitive_tr['race'].values)\n",
    "    fg_calib_test = ut.calibration(fg_y_test, y_test.flatten(),x_sensitive_tr['race'].values)\n",
    "\n",
    "    print('train calibration difference: ' + str(fg_calib_train))\n",
    "    print('test calibration difference: ' + str(fg_calib_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
