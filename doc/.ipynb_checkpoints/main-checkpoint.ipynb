{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05448df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dython.nominal import associations\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from itertools import chain\n",
    "import math\n",
    "from random import seed, shuffle\n",
    "from scipy.optimize import minimize \n",
    "from multiprocessing import Pool, Process, Queue\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score as accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbc222",
   "metadata": {},
   "source": [
    "# Project 4 - A3 and A6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b85ad",
   "metadata": {},
   "source": [
    "## A3 Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8defb05",
   "metadata": {},
   "source": [
    "## A6 Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = '../data/compas-scores-two-years.csv'\n",
    "df = pd.read_csv(raw_data)\n",
    "data = df[(df['race']=='African-American')|(df['race']=='Caucasian')]\n",
    "data.drop(['violent_recid','vr_charge_degree','vr_case_number','vr_offense_date','vr_charge_desc',\n",
    "          'c_arrest_date','r_jail_out','r_jail_in','r_days_from_arrest','r_charge_desc',\n",
    "          'r_offense_date','r_case_number','r_charge_degree'], axis=1,inplace=True)\n",
    "data['c_offense_date'] = pd.to_datetime(data['c_offense_date'])\n",
    "data['c_jail_in']= pd.to_datetime(data['c_jail_in'])\n",
    "data['c_jail_out']= pd.to_datetime(data['c_jail_out'])\n",
    "data['out_custody']= pd.to_datetime(data['out_custody'])\n",
    "data['in_custody']= pd.to_datetime(data['in_custody'])\n",
    "data['screening_date']= pd.to_datetime(data['screening_date'])\n",
    "data['compas_screening_date']= pd.to_datetime(data['compas_screening_date'])\n",
    "data['v_screening_date']= pd.to_datetime(data['v_screening_date'])\n",
    "data['c_days_from_compas'] = data['c_days_from_compas'] .fillna(data['c_days_from_compas'].mode()[0])\n",
    "X = data.drop(['id','two_year_recid','c_case_number','sex','dob','name'], axis=1)\n",
    "X.set_index(data.id,inplace=True)\n",
    "af = data[data.race=='African-American']\n",
    "ca = data[data.race =='Caucasian']\n",
    "rate_af = round(af[af['two_year_recid']==1].shape[0]/af.shape[0],2)\n",
    "rate_ca = round(ca[ca['two_year_recid']==1].shape[0]/af.shape[0],2)\n",
    "print(f'The rate of Recidivism for African-American is {rate_af}\\nThe rate of Recidivism for Caucasian is {rate_ca}')\n",
    "print(f'The Corrected Recidivism rate should be {(rate_af+rate_ca)/2:,} ')\n",
    "y = data[['two_year_recid']]\n",
    "y.set_index(data.id,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr()\n",
    "fig,ax = plt.subplots(figsize=(15,12))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2be0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_new = enc.fit(X)\n",
    "X_new = enc.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=.3,random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=44).fit(X_train, y_train) \n",
    "y_pred_test = forest.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "cali_X = X.loc[y_test.index]\n",
    "cali_X['label'] = y_test\n",
    "cali_X['pred'] = y_pred_test\n",
    "af_X = cali_X[cali_X.race=='African-American']\n",
    "ca_X =  cali_X[cali_X.race=='Caucasian']\n",
    "print(np.abs(accuracy_score(af_X.label, af_X.pred)-accuracy_score(ca_X.label, ca_X.pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2496bd",
   "metadata": {},
   "source": [
    "The model showed that African-American has a higher Recidivism rate compared to Caucasian, and in reality the rate should be pretty much the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['first','last','age_cat','race','c_charge_degree','c_charge_desc','type_of_assessment',\n",
    "                       'score_text','v_type_of_assessment','v_score_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac02f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column= X[categorical_features]\n",
    "categorical_df = selected_column.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69aa851",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_correlation= associations(categorical_df, filename= 'categorical_correlation.png', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5944e8",
   "metadata": {},
   "source": [
    "Here we set the correlation threshold to be no less than 0.2, and we get the $e_{i}$ to be first, last, c_charge_desc, score_text and v_score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ebfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_list = ['first', 'last', 'c_charge_desc', 'score_text' , 'v_score_text']\n",
    "exclude_e_s = [\n",
    " 'compas_screening_date',\n",
    " 'age',\n",
    " 'age_cat',\n",
    " 'juv_fel_count',\n",
    " 'decile_score',\n",
    " 'juv_misd_count',\n",
    " 'juv_other_count',\n",
    " 'priors_count',\n",
    " 'days_b_screening_arrest',\n",
    " 'c_jail_in',\n",
    " 'c_jail_out',\n",
    " 'c_offense_date',\n",
    " 'c_days_from_compas',\n",
    " 'c_charge_degree',\n",
    " 'is_recid',\n",
    " 'is_violent_recid',\n",
    " 'type_of_assessment',\n",
    " 'decile_score.1',\n",
    " 'screening_date',\n",
    " 'v_type_of_assessment',\n",
    " 'v_decile_score',\n",
    " 'v_screening_date',\n",
    " 'in_custody',\n",
    " 'out_custody',\n",
    " 'priors_count.1',\n",
    " 'start',\n",
    " 'end',\n",
    " 'event']\n",
    "e = X[e_list]\n",
    "new_X = X[exclude_e_s]\n",
    "s = X[['race']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d382d",
   "metadata": {},
   "source": [
    "### Handling Conditional Discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabc1c2",
   "metadata": {},
   "source": [
    "![a3.jpg](../figs/a3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X,e):\n",
    "    e_list = list(e.keys())\n",
    "    X_i = []\n",
    "    for i in range(len(e_list)):\n",
    "        X[e_list[i]] = e[e_list[i]]\n",
    "        X_i.append(X)\n",
    "    return X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0005b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = partition(new_X,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74a1f7",
   "metadata": {},
   "source": [
    "![a4.jpg](../figs/a4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c026af",
   "metadata": {},
   "source": [
    "For Algorithm 4, $p^\\star(+|e_i)$, $p(+|e_i,\\text{gender})$ is changed each time for different i, I have no idea what $G_i$ is the description is too abstract, as so I will define $G_i$ as a constant $C$ (Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceildiv(a, b):\n",
    "    return -(a // -b)\n",
    "def delta(item, y_pred, y_prob, G_i = 12):\n",
    "    \n",
    "    item_copy = item.copy()\n",
    "    item_copy['label'] = y_pred\n",
    "    af = item_copy[item_copy.race=='African-American']\n",
    "    ca = item_copy[item_copy.race =='Caucasian']\n",
    "    rate_af = round(af[af['label']==1].shape[0]/af.shape[0],2)\n",
    "    rate_ca = round(ca[ca['label']==1].shape[0]/ca.shape[0],2)\n",
    "    p_star = (rate_af+rate_ca)/2\n",
    "    threshold = np.abs(rate_af-p_star)\n",
    "    \n",
    "    test_df = pd.DataFrame(y_prob,columns=['No','Yes'])\n",
    "    test_df.set_index(item.index,inplace=True)\n",
    "    test_df['race']=item['race']\n",
    "    test_df['label'] = y_pred\n",
    "    temp = test_df[(np.abs(test_df.Yes - test_df.No)<=G_i*threshold)]\n",
    "#     print(temp.shape[0],threshold)\n",
    "    for i in range(temp.shape[0]):\n",
    "        if temp.race.iloc[i] == 'African-American' and temp.Yes.iloc[i] > temp.No.iloc[i]:\n",
    "            temp.label.iloc[i] = 0\n",
    "        elif temp.race.iloc[i] == 'Caucasian' and temp.Yes.iloc[i] < temp.No.iloc[i]:\n",
    "            temp.label.iloc[i] = 1\n",
    "    \n",
    "    item_copy['label'].loc[temp.index] = temp.label\n",
    "    \n",
    "    return item_copy\n",
    "def delta2(item, y_pred, y_prob, G_i = 6):\n",
    "    \n",
    "    item_copy = item.copy()\n",
    "    item_copy['label'] = y_pred\n",
    "    af = item_copy[item_copy.race=='African-American']\n",
    "    ca = item_copy[item_copy.race =='Caucasian']\n",
    "    rate_af = round(af[af['label']==1].shape[0]/af.shape[0],2)\n",
    "    rate_ca = round(ca[ca['label']==1].shape[0]/ca.shape[0],2)\n",
    "    p_star = (rate_af+rate_ca)/2\n",
    "    threshold = np.abs(rate_af-p_star)\n",
    "    \n",
    "    test_df = pd.DataFrame(y_prob,columns=['No','Yes'])\n",
    "    test_df.set_index(item.index,inplace=True)\n",
    "    test_df['race']=item['race']\n",
    "    test_df['label'] = y_pred\n",
    "    temp = test_df[(np.abs(test_df.Yes - test_df.No)<=G_i*threshold)]\n",
    "#     print(temp.shape[0],threshold)\n",
    "    temp_dic = temp[['race','label']].value_counts().to_dict()\n",
    "    \n",
    "    aa_0,aa_1,ca_0,ca_1 = 0,0,0,0\n",
    "    for key, value in zip(temp_dic.keys(),temp_dic.values()):\n",
    "        if key == ('African-American', 1):\n",
    "            aa_1 = ceildiv(value,2)\n",
    "        if key == ('African-American', 0):\n",
    "            aa_0 = ceildiv(value,2)       \n",
    "        if key == ('Caucasian', 1):\n",
    "            ca_1 = ceildiv(value,2)        \n",
    "        if key == ('Caucasian', 0):\n",
    "            ca_0 = ceildiv(value,2)\n",
    "\n",
    "    if aa_1>aa_0:\n",
    "        aa_replace = aa_0\n",
    "    else:\n",
    "        aa_replace = aa_1\n",
    "\n",
    "    if ca_1>ca_0:\n",
    "        ca_replace = ca_0\n",
    "    else:\n",
    "        ca_replace = ca_1\n",
    "\n",
    "    count_aa = 0\n",
    "    count_ca = 0\n",
    "\n",
    "    while(count_aa<aa_replace):\n",
    "        for idx in list(temp.index):\n",
    "            if temp.race.loc[idx] == 'African-American' and temp.label.loc[idx] ==1:\n",
    "                temp.label.loc[idx] = 0\n",
    "                count_aa +=1\n",
    "\n",
    "    while(count_ca<ca_replace):\n",
    "        for idx in list(temp.index):\n",
    "            if temp.race.loc[idx] == 'Caucasian' and temp.label.loc[idx] ==0:\n",
    "                temp.label.loc[idx] = 1\n",
    "                count_ca +=1\n",
    "    \n",
    "    item_copy['label'].loc[temp.index] = temp.label\n",
    "    \n",
    "    return item_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248f2fe",
   "metadata": {},
   "source": [
    "## Algorithm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcbe7d0",
   "metadata": {},
   "source": [
    "![a1.jpg](../figs/a1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_massaging(X,s,e,y):\n",
    "    X['race'] = s\n",
    "    X_i_list =partition(X,e)\n",
    "    df_list = []\n",
    "    pd_list = []\n",
    "    for item in X_i_list:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        X_new = enc.fit(item)\n",
    "        X_new = enc.transform(item)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=.3,random_state=5)\n",
    "        forest = RandomForestClassifier(random_state=44).fit(X_train, y_train) \n",
    "        y_pred = forest.predict(X_new)\n",
    "        y_prob = forest.predict_proba(X_new)\n",
    "        temp_df = delta(item,y_pred,y_prob)\n",
    "        pd_list.append(temp_df)\n",
    "        df_list.append(temp_df[['label']])\n",
    "    \n",
    "    # Here we take vote \n",
    "    \n",
    "    result = pd.concat(df_list,axis = 1)\n",
    "    result.loc[result.sum(axis=1)<=2,'new_label'] = 0\n",
    "    result.loc[result.sum(axis=1)>=3,'new_label'] = 1\n",
    "    X['new_label'] = result.new_label\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07804f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_X = local_massaging(new_X,s,e,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401be6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "af = New_X[New_X.race=='African-American']\n",
    "ca = New_X[New_X.race =='Caucasian']\n",
    "rate_af = round(af[af['new_label']==1].shape[0]/af.shape[0],2)\n",
    "rate_ca = round(ca[ca['new_label']==1].shape[0]/ca.shape[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_af,rate_ca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c02fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see the discrimation is being balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_y = New_X.new_label\n",
    "New_X_copy = New_X.copy()\n",
    "New_X_copy.drop(['new_label'],axis=1,inplace=True)\n",
    "X_new = enc.fit(New_X_copy)\n",
    "X_new = enc.transform(New_X_copy)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,New_y,test_size=.3,random_state=42)\n",
    "forest = RandomForestClassifier(random_state=42).fit(X_train, y_train) \n",
    "y_pred_test = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3102ac7d",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feac34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "cali_X = New_X.loc[y_test.index]\n",
    "cali_X['label'] = y_test\n",
    "cali_X['pred'] = y_pred_test\n",
    "af_X = cali_X[cali_X.race=='African-American']\n",
    "ca_X =  cali_X[cali_X.race=='Caucasian']\n",
    "print(np.abs(accuracy_score(af_X.label, af_X.pred)-accuracy_score(ca_X.label, ca_X.pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47defe",
   "metadata": {},
   "source": [
    "### Algorithm 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826205b0",
   "metadata": {},
   "source": [
    "![a2.jpg](../figs/a2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_preferential_sampking(X,s,e,y):\n",
    "    X['race'] = s\n",
    "    X_i_list =partition(X,e)\n",
    "    df_list = []\n",
    "    pd_list = []\n",
    "    for item in X_i_list:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        X_new = enc.fit(item)\n",
    "        X_new = enc.transform(item)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=.3,random_state=42)\n",
    "        forest = RandomForestClassifier(random_state = 88).fit(X_train, y_train) \n",
    "        y_pred = forest.predict(X_new)\n",
    "        y_prob = forest.predict_proba(X_new)\n",
    "        temp_df = delta2(item,y_pred,y_prob,6)\n",
    "        pd_list.append(temp_df)\n",
    "        df_list.append(temp_df[['label']])\n",
    "    \n",
    "    # Here we take vote \n",
    "    \n",
    "    result = pd.concat(df_list,axis = 1)\n",
    "    result.loc[result.sum(axis=1)<=2,'new_label'] = 0\n",
    "    result.loc[result.sum(axis=1)>=3,'new_label'] = 1\n",
    "    X['new_label'] = result.new_label\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_New = local_preferential_sampling(new_X,s,e,y)\n",
    "af = X_New[X_New.race=='African-American']\n",
    "ca = X_New[X_New.race =='Caucasian']\n",
    "rate_af = round(af[af['new_label']==1].shape[0]/af.shape[0],2)\n",
    "rate_ca = round(ca[ca['new_label']==1].shape[0]/ca.shape[0],2)\n",
    "rate_af,rate_ca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fae040",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_New = X_New.new_label\n",
    "X_New_copy = X_New.copy()\n",
    "X_New_copy.drop(['new_label'],axis=1,inplace=True)\n",
    "X_new = enc.fit(X_New_copy)\n",
    "X_new = enc.transform(X_New_copy)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,y_New,test_size=.3,random_state=42)\n",
    "forest = RandomForestClassifier(random_state=42).fit(X_train, y_train) \n",
    "y_pred_test = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91df3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "cali_X = X_New.loc[y_test.index]\n",
    "cali_X['label'] = y_test\n",
    "cali_X['pred'] = y_pred_test\n",
    "af_X = cali_X[cali_X.race=='African-American']\n",
    "ca_X =  cali_X[cali_X.race=='Caucasian']\n",
    "print(np.abs(accuracy_score(af_X.label, af_X.pred)-accuracy_score(ca_X.label, ca_X.pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b32a0",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "We can see that the accuracy and Calibration slightly decreased after modified algorithms but in return of a good elimination towards bad discrimination. After all we conclude that the drop of accuracy is worth the shot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
